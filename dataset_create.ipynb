{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbad0ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2 as cv\n",
    "from PIL import Image\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ee1ff0",
   "metadata": {},
   "source": [
    "# Pathing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebda0465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imagenet bbox\n",
    "bbox_path = 'E:/CV_Project/imagenet/bbox/Annotation'\n",
    "# imagenet\n",
    "image_cats = 'C:/Users/Belda/Documents/Harvard/Comp_Vision/Project/imageNetCatNumber.txt'\n",
    "imgnet_imgs = 'E:/CV_Project/imagenet/ILSVRC/Data/DET/train/ILSVRC2013_train'\n",
    "# coco as pascal voc\n",
    "bear_xml = 'F:/Det_Project/train_bears'\n",
    "person_xml = 'F:/Det_Project/train_person'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef722f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is to map old ids to my new categories\n",
    "# 0:background\n",
    "# 1:fox\n",
    "# 2:bear\n",
    "# 3:hog\n",
    "# 4:dog\n",
    "# 5:person\n",
    "label_map = {'background':0, 'fox':1, 'bear':2, 'n02119789':1, 'n02119022':1,\n",
    "            'n02120505':1, 'n02133161':2, 'n02395406':3, 'n02110185':4, \n",
    "             'n02110063':4, 'n02109047':4, 'person':5}\n",
    "# getting counts for images to balance training across all cats\n",
    "# ~1K images to train\n",
    "count_map = {1:75, 2:100, 3:200, 4:67, 5:200}\n",
    "output_folder = 'F:/Det_Project/full_dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03af5692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is from project in utils.py\n",
    "# it will parse the xml and return new id map along with boxes\n",
    "def parse_annotation(annotation_path):\n",
    "    tree = ET.parse(annotation_path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    boxes = list()\n",
    "    labels = list()\n",
    "    difficulties = list()\n",
    "    for object in root.iter('object'):\n",
    "        # there are some errors in the XML files\n",
    "        # for the coco format annotations that were ported\n",
    "        try:\n",
    "            difficult = int(object.find('difficult').text == '1')\n",
    "            label = object.find('name').text.lower().strip()\n",
    "            bbox = object.find('bndbox')\n",
    "            xmin = int(bbox.find('xmin').text)\n",
    "            ymin = int(bbox.find('ymin').text)\n",
    "            xmax = int(bbox.find('xmax').text)\n",
    "            ymax = int(bbox.find('ymax').text)\n",
    "        except: \n",
    "            continue\n",
    "        if label not in label_map:\n",
    "            continue\n",
    "        if not bbox or not xmin or not ymin or not xmax or not ymax:\n",
    "            continue\n",
    "\n",
    "        boxes.append([xmin, ymin, xmax, ymax])\n",
    "        labels.append(label_map[label])\n",
    "        difficulties.append(difficult)\n",
    "\n",
    "    return {'boxes':boxes, 'labels':labels, 'difficulties':difficulties}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b84c733",
   "metadata": {},
   "source": [
    "# coco as pascal voc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f6eb1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImgObjFromCOCO(path_dir, image_count):\n",
    "    files = os.listdir(path_dir)\n",
    "    train_images = list()\n",
    "    train_objects = list()\n",
    "    test_images = list()\n",
    "    test_objects = list()\n",
    "    img_index = 0\n",
    "    for file in files:\n",
    "        if '.xml' in file:\n",
    "            # checking for bad parsing,\n",
    "            # empty labels or boxes\n",
    "            bad_parse = 0\n",
    "            try:\n",
    "                annote = parse_annotation(os.path.join(path_dir, file))\n",
    "            except: bad_parse = 1\n",
    "            if bad_parse:\n",
    "                continue\n",
    "            if not annote['boxes'] or not annote['labels']:\n",
    "                continue\n",
    "                \n",
    "            filename = file.split('.xml')[0]\n",
    "            if img_index <= image_count:\n",
    "                train_images.append(os.path.join(path_dir, filename+'.jpg'))\n",
    "                train_objects.append(annote)\n",
    "            else:\n",
    "                test_images.append(os.path.join(path_dir, filename+'.jpg'))\n",
    "                test_objects.append(annote)\n",
    "            img_index = img_index + 1\n",
    "    return train_images, train_objects, test_images, test_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53e5c314",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_count = count_map[label_map['bear']]\n",
    "bear_train_images, bear_train_objects, bear_test_images, bear_test_objects = getImgObjFromCOCO(bear_xml, image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c83291a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 101 bear images to train with.\n"
     ]
    }
   ],
   "source": [
    "print('There are {} bear images to train with.'.format(len(bear_train_images)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2740286f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_count = count_map[label_map['person']]\n",
    "person_train_images, person_train_objects, person_test_images, person_test_objects = getImgObjFromCOCO(person_xml, image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46fdf48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 198 person images to train with.\n"
     ]
    }
   ],
   "source": [
    "print('There are {} person images to train with.'.format(len(person_train_images)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97bb33a",
   "metadata": {},
   "source": [
    "# Imagenet images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb842ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (image_cats) as f:\n",
    "    categories = f.read().splitlines()\n",
    "\n",
    "# the image list will just be absolute filepaths\n",
    "imgnet_train_images = list()\n",
    "imgnet_train_objects = list()\n",
    "imgnet_test_images = list()\n",
    "imgnet_test_objects = list()\n",
    "flag = 0\n",
    "\n",
    "for cat in categories:\n",
    "    files = os.listdir(os.path.join(bbox_path, cat))\n",
    "    image_count = count_map[label_map[cat]]\n",
    "    img_index = 0\n",
    "    for file in files:\n",
    "        filename = file.split('.xml')[0]\n",
    "        img_path = os.path.join(imgnet_imgs, cat, filename+'.JPEG')\n",
    "        # need to check for correlated image\n",
    "        # there is a discrepency between DET dataset and bounding box dataset\n",
    "        if os.path.exists(img_path):\n",
    "            # need to check for bad parsing there's bad XML in Imagenet\n",
    "            bad_parse = 0\n",
    "            try:\n",
    "                annote = parse_annotation(os.path.join(bbox_path, cat, file))\n",
    "            except: bad_parse = 1\n",
    "            if bad_parse:\n",
    "                continue\n",
    "            if img_index <= image_count:\n",
    "                imgnet_train_images.append(img_path)\n",
    "                imgnet_train_objects.append(annote)\n",
    "            else:\n",
    "                imgnet_test_images.append(img_path)\n",
    "                imgnet_test_objects.append(annote)\n",
    "        img_index = img_index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a240c5c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 720 images from Imagenet.\n"
     ]
    }
   ],
   "source": [
    "print('There are {} images from Imagenet.'.format(len(imgnet_train_images)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b165279",
   "metadata": {},
   "source": [
    "# Combining COCO and Imagenet sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "768bc726",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_images = imgnet_train_images\n",
    "training_images.extend(bear_train_images[:count_map[label_map['bear']]])\n",
    "training_images.extend(person_train_images[:count_map[label_map['person']]])\n",
    "\n",
    "training_objects = imgnet_train_objects\n",
    "training_objects.extend(bear_train_objects[:count_map[label_map['bear']]])\n",
    "training_objects.extend(person_train_objects[:count_map[label_map['person']]])\n",
    "\n",
    "testing_images = imgnet_test_images\n",
    "testing_images.extend(bear_test_images[count_map[label_map['bear']]:])\n",
    "testing_images.extend(person_test_images[count_map[label_map['person']]:])\n",
    "\n",
    "testing_objects = imgnet_test_objects\n",
    "testing_objects.extend(bear_test_objects[count_map[label_map['bear']]:])\n",
    "testing_objects.extend(person_test_objects[count_map[label_map['person']]:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94042af3",
   "metadata": {},
   "source": [
    "# writing dataset to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be80a617",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(output_folder, 'label_map.json'), 'w') as j:\n",
    "    json.dump(label_map, j)\n",
    "with open(os.path.join(output_folder, 'TRAIN_images.json'), 'w') as j:\n",
    "    json.dump(training_images, j)\n",
    "with open(os.path.join(output_folder, 'TRAIN_objects.json'), 'w') as j:\n",
    "    json.dump(training_objects, j)\n",
    "with open(os.path.join(output_folder, 'TEST_images.json'), 'w') as j:\n",
    "    json.dump(testing_images, j)\n",
    "with open(os.path.join(output_folder, 'TEST_objects.json'), 'w') as j:\n",
    "    json.dump(testing_objects, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3daad488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1018 images to train from.\n",
      "There are 3811 images to test from.\n"
     ]
    }
   ],
   "source": [
    "print('There are {} images to train from.'.format(len(training_images)))\n",
    "print('There are {} images to test from.'.format(len(testing_images)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
